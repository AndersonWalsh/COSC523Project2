{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0d354",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-14T19:17:11.378564Z",
     "iopub.status.busy": "2024-11-14T19:17:11.378262Z",
     "iopub.status.idle": "2024-11-14T19:18:12.292604Z",
     "shell.execute_reply": "2024-11-14T19:18:12.291406Z"
    },
    "papermill": {
     "duration": 60.924718,
     "end_time": "2024-11-14T19:18:12.295217",
     "exception": false,
     "start_time": "2024-11-14T19:17:11.370499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install keras-core --upgrade\n",
    "!pip install -q keras-nlp --upgrade\n",
    "!pip install keras-nlp==0.6.1\n",
    "!pip install nlpaug\n",
    "!pip install nltk\n",
    "\n",
    "\n",
    "# This sample uses Keras Core, the multi-backend version of Keras.\n",
    "# The selected backend is TensorFlow (other supported backends are 'jax' and 'torch')\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e8022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:18:12.315627Z",
     "iopub.status.busy": "2024-11-14T19:18:12.315254Z",
     "iopub.status.idle": "2024-11-14T19:18:30.113760Z",
     "shell.execute_reply": "2024-11-14T19:18:30.112912Z"
    },
    "papermill": {
     "duration": 17.811422,
     "end_time": "2024-11-14T19:18:30.115965",
     "exception": false,
     "start_time": "2024-11-14T19:18:12.304543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import keras_core as keras\n",
    "import keras_nlp\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"KerasNLP version:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe13cb",
   "metadata": {
    "papermill": {
     "duration": 0.009078,
     "end_time": "2024-11-14T19:18:30.134546",
     "exception": false,
     "start_time": "2024-11-14T19:18:30.125468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the Disaster Tweets\n",
    "Let's have a look at the train and test dataset.\n",
    "\n",
    "They contain:\n",
    "- id\n",
    "- keyword: A keyword from that tweet (although this may be blank!)\n",
    "- location: The location the tweet was sent from (may also be blank)\n",
    "- text: The text of a tweet\n",
    "- target: 1 if the tweet is a real disaster or 0 if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28f865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:18:30.154882Z",
     "iopub.status.busy": "2024-11-14T19:18:30.154520Z",
     "iopub.status.idle": "2024-11-14T19:19:14.930580Z",
     "shell.execute_reply": "2024-11-14T19:19:14.929511Z"
    },
    "papermill": {
     "duration": 44.797883,
     "end_time": "2024-11-14T19:19:14.941843",
     "exception": false,
     "start_time": "2024-11-14T19:18:30.143960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure NLTK packages are downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n",
    "\n",
    "# Create a synonym augmentation object\n",
    "aug = naw.SynonymAug(aug_src='wordnet', aug_max=2)\n",
    "\n",
    "df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda x: ' '.join(aug.augment(x)) if isinstance(aug.augment(x), list) else aug.augment(x))\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(lambda x: ' '.join(aug.augment(x)) if isinstance(aug.augment(x), list) else aug.augment(x))\n",
    "\n",
    "\n",
    "print('Training Set Shape = {}'.format(df_train.shape))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Shape = {}'.format(df_test.shape))\n",
    "print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e173a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:19:14.962132Z",
     "iopub.status.busy": "2024-11-14T19:19:14.961831Z",
     "iopub.status.idle": "2024-11-14T19:19:14.975839Z",
     "shell.execute_reply": "2024-11-14T19:19:14.974988Z"
    },
    "papermill": {
     "duration": 0.026457,
     "end_time": "2024-11-14T19:19:14.977779",
     "exception": false,
     "start_time": "2024-11-14T19:19:14.951322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b94d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:19:14.998750Z",
     "iopub.status.busy": "2024-11-14T19:19:14.998461Z",
     "iopub.status.idle": "2024-11-14T19:19:15.007723Z",
     "shell.execute_reply": "2024-11-14T19:19:15.006837Z"
    },
    "papermill": {
     "duration": 0.022406,
     "end_time": "2024-11-14T19:19:15.009837",
     "exception": false,
     "start_time": "2024-11-14T19:19:14.987431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d22182",
   "metadata": {
    "papermill": {
     "duration": 0.009695,
     "end_time": "2024-11-14T19:19:15.030488",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.020793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d09db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:19:15.051305Z",
     "iopub.status.busy": "2024-11-14T19:19:15.051029Z",
     "iopub.status.idle": "2024-11-14T19:19:15.076055Z",
     "shell.execute_reply": "2024-11-14T19:19:15.074997Z"
    },
    "papermill": {
     "duration": 0.037687,
     "end_time": "2024-11-14T19:19:15.078043",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.040356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[\"length\"] = df_train[\"text\"].apply(lambda x : len(x))\n",
    "df_test[\"length\"] = df_test[\"text\"].apply(lambda x : len(x))\n",
    "\n",
    "print(\"Train Length Stat\")\n",
    "print(df_train[\"length\"].describe())\n",
    "print()\n",
    "\n",
    "print(\"Test Length Stat\")\n",
    "print(df_test[\"length\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442eb03",
   "metadata": {
    "papermill": {
     "duration": 0.009737,
     "end_time": "2024-11-14T19:19:15.098114",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.088377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you want to know more information about the data, you can grab useful information [here](https://www.kaggle.com/code/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert)\n",
    "\n",
    "Note that all the tweets are in english."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692eb016",
   "metadata": {
    "papermill": {
     "duration": 0.010156,
     "end_time": "2024-11-14T19:19:15.118395",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.108239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73bb10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:19:15.139443Z",
     "iopub.status.busy": "2024-11-14T19:19:15.139186Z",
     "iopub.status.idle": "2024-11-14T19:19:15.143865Z",
     "shell.execute_reply": "2024-11-14T19:19:15.143095Z"
    },
    "papermill": {
     "duration": 0.017473,
     "end_time": "2024-11-14T19:19:15.145828",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.128355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_TRAINING_EXAMPLES = df_train.shape[0]\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.2\n",
    "STEPS_PER_EPOCH = int(NUM_TRAINING_EXAMPLES)*TRAIN_SPLIT // BATCH_SIZE\n",
    "\n",
    "EPOCHS = 2\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c805462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:19:15.166813Z",
     "iopub.status.busy": "2024-11-14T19:19:15.166577Z",
     "iopub.status.idle": "2024-11-14T19:19:15.173350Z",
     "shell.execute_reply": "2024-11-14T19:19:15.172681Z"
    },
    "papermill": {
     "duration": 0.019506,
     "end_time": "2024-11-14T19:19:15.175303",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.155797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train[\"text\"]\n",
    "y = df_train[\"target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=VAL_SPLIT, random_state=42)\n",
    "\n",
    "X_test = df_test[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e8130",
   "metadata": {
    "papermill": {
     "duration": 0.009723,
     "end_time": "2024-11-14T19:19:15.195068",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.185345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load a DistilBERT model from Keras NLP\n",
    "\n",
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT.\n",
    "\n",
    "The BertClassifier model can be configured with a preprocessor layer, in which case it will automatically apply preprocessing to raw inputs during fit(), predict(), and evaluate(). This is done by default when creating the model with from_preset().\n",
    "\n",
    "We will choose DistilBERT model.that learns a distilled (approximate) version of BERT, retaining 97% performance but using only half the number of parameters ([paper](https://arxiv.org/abs/1910.01108)). \n",
    "\n",
    "It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERTâ€™s performances as measured on the GLUE language understanding benchmark.\n",
    "\n",
    "Specifically, it doesn't have token-type embeddings, pooler and retains only half of the layers from Google's BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f79d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:19:15.216109Z",
     "iopub.status.busy": "2024-11-14T19:19:15.215853Z",
     "iopub.status.idle": "2024-11-14T19:19:23.577754Z",
     "shell.execute_reply": "2024-11-14T19:19:23.576943Z"
    },
    "papermill": {
     "duration": 8.374732,
     "end_time": "2024-11-14T19:19:23.579733",
     "exception": false,
     "start_time": "2024-11-14T19:19:15.205001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a DistilBERT model.\n",
    "preset= \"distil_bert_base_en_uncased\"\n",
    "\n",
    "# Use a shorter sequence length.\n",
    "preprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(preset,\n",
    "                                                                   sequence_length=160,\n",
    "                                                                   name=\"preprocessor_4_tweets\"\n",
    "                                                                  )\n",
    "\n",
    "# Pretrained classifier.\n",
    "classifier = keras_nlp.models.DistilBertClassifier.from_preset(preset,\n",
    "                                                               preprocessor = preprocessor, \n",
    "                                                               num_classes=2)\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72199913",
   "metadata": {
    "papermill": {
     "duration": 0.013167,
     "end_time": "2024-11-14T19:19:23.606621",
     "exception": false,
     "start_time": "2024-11-14T19:19:23.593454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train your own model, fine-tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73e40d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:19:23.634510Z",
     "iopub.status.busy": "2024-11-14T19:19:23.634220Z",
     "iopub.status.idle": "2024-11-14T19:23:00.205431Z",
     "shell.execute_reply": "2024-11-14T19:23:00.204566Z"
    },
    "papermill": {
     "duration": 216.589027,
     "end_time": "2024-11-14T19:23:00.208980",
     "exception": false,
     "start_time": "2024-11-14T19:19:23.619953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), #'binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    metrics= [\"accuracy\"]  \n",
    ")\n",
    "\n",
    "# Fit\n",
    "history = classifier.fit(x=X_train,\n",
    "                         y=y_train,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=EPOCHS, \n",
    "                         validation_data=(X_val, y_val)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74e19a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:23:00.296495Z",
     "iopub.status.busy": "2024-11-14T19:23:00.295612Z",
     "iopub.status.idle": "2024-11-14T19:23:00.302417Z",
     "shell.execute_reply": "2024-11-14T19:23:00.301526Z"
    },
    "papermill": {
     "duration": 0.052104,
     "end_time": "2024-11-14T19:23:00.304401",
     "exception": false,
     "start_time": "2024-11-14T19:23:00.252297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def displayConfusionMatrix(y_true, y_pred, dataset):\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true,\n",
    "        np.argmax(y_pred, axis=1),\n",
    "        display_labels=[\"Not Disaster\",\"Disaster\"],\n",
    "        cmap=plt.cm.Blues\n",
    "    )\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, np.argmax(y_pred, axis=1)).ravel()\n",
    "    f1_score = tp / (tp+((fn+fp)/2))\n",
    "\n",
    "    disp.ax_.set_title(\"Confusion Matrix on \" + dataset + \" Dataset -- F1 Score: \" + str(f1_score.round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260dd7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:23:00.389763Z",
     "iopub.status.busy": "2024-11-14T19:23:00.389444Z",
     "iopub.status.idle": "2024-11-14T19:23:21.720334Z",
     "shell.execute_reply": "2024-11-14T19:23:21.719336Z"
    },
    "papermill": {
     "duration": 21.376139,
     "end_time": "2024-11-14T19:23:21.722509",
     "exception": false,
     "start_time": "2024-11-14T19:23:00.346370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_train = classifier.predict(X_train)\n",
    "\n",
    "displayConfusionMatrix(y_train, y_pred_train, \"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bc41c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:23:21.839836Z",
     "iopub.status.busy": "2024-11-14T19:23:21.839519Z",
     "iopub.status.idle": "2024-11-14T19:23:29.790114Z",
     "shell.execute_reply": "2024-11-14T19:23:29.789286Z"
    },
    "papermill": {
     "duration": 8.010788,
     "end_time": "2024-11-14T19:23:29.792263",
     "exception": false,
     "start_time": "2024-11-14T19:23:21.781475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_val = classifier.predict(X_val)\n",
    "\n",
    "displayConfusionMatrix(y_val, y_pred_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c06688",
   "metadata": {
    "papermill": {
     "duration": 0.061476,
     "end_time": "2024-11-14T19:23:29.917697",
     "exception": false,
     "start_time": "2024-11-14T19:23:29.856221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate the submission file \n",
    "\n",
    "For each tweets in the test set, we predict if the given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n",
    "\n",
    "The `submission.csv` file uses the following format:\n",
    "`id,target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197fe4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:23:30.041241Z",
     "iopub.status.busy": "2024-11-14T19:23:30.040855Z",
     "iopub.status.idle": "2024-11-14T19:23:30.057261Z",
     "shell.execute_reply": "2024-11-14T19:23:30.056235Z"
    },
    "papermill": {
     "duration": 0.080511,
     "end_time": "2024-11-14T19:23:30.059376",
     "exception": false,
     "start_time": "2024-11-14T19:23:29.978865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8b2d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:23:30.191509Z",
     "iopub.status.busy": "2024-11-14T19:23:30.190569Z",
     "iopub.status.idle": "2024-11-14T19:23:42.492940Z",
     "shell.execute_reply": "2024-11-14T19:23:42.491812Z"
    },
    "papermill": {
     "duration": 12.371602,
     "end_time": "2024-11-14T19:23:42.495385",
     "exception": false,
     "start_time": "2024-11-14T19:23:30.123783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = np.argmax(classifier.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f6f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:23:42.636051Z",
     "iopub.status.busy": "2024-11-14T19:23:42.635379Z",
     "iopub.status.idle": "2024-11-14T19:23:42.652417Z",
     "shell.execute_reply": "2024-11-14T19:23:42.651516Z"
    },
    "papermill": {
     "duration": 0.089308,
     "end_time": "2024-11-14T19:23:42.654324",
     "exception": false,
     "start_time": "2024-11-14T19:23:42.565016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd9328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T19:23:42.797337Z",
     "iopub.status.busy": "2024-11-14T19:23:42.796942Z",
     "iopub.status.idle": "2024-11-14T19:23:42.810371Z",
     "shell.execute_reply": "2024-11-14T19:23:42.809556Z"
    },
    "papermill": {
     "duration": 0.085802,
     "end_time": "2024-11-14T19:23:42.812291",
     "exception": false,
     "start_time": "2024-11-14T19:23:42.726489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30528,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 404.90017,
   "end_time": "2024-11-14T19:23:46.463213",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-14T19:17:01.563043",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
